---
title: Semantic Search
description: Retrieve relevant images and objects based on natural language and contextual understanding—beyond keyword matching.
---

<Card title="How this Helps" icon="lightbulb">
  Semantic Search helps you discover relevant visual data based on concepts and context—not just labels or keywords. It's ideal for exploration, discovery, and working with unstructured datasets.
</Card>

---

## What Is Semantic Search?

Semantic Search allows you to retrieve images and objects based on the **meaning and context** of your text queries, instead of relying on exact keyword matches. This enables more **intuitive**, **concept-driven** exploration of your dataset.

It works by matching your queries against metadata generated by **Visual Layer’s enrichment models**, including:

- `VL-Image Semantic Search`
- `VL-Object Semantic Search`

These models interpret visual content and associate it with descriptive embeddings, enabling deeper, context-aware querying.

---

## How It Works

- Queries are matched against **generated semantic metadata** (not manual tags).
- Available at both the **image** and **object** level, depending on your current view.
- Requires enrichment using either `VL-Image Semantic Search` or `VL-Object Semantic Search`.
- Ideal for:
  - Surfacing subtle visual patterns
  - Exploring abstract ideas like "urban solitude" or "festival crowd"
  - Navigating datasets with minimal labeling

---

## Example Queries

Try using natural, descriptive phrases. The system is designed to parse both broad concepts and specific scenes:

<Card title="Simple Query">
"sunset over mountains"
</Card>

<Card title="Detailed Scene">
"bright sunset over rocky mountains with clear sky"
</Card>

<Card title="Combined Attributes">
"blue sports car on city street at night"
</Card>

<Tip>
More detailed phrases yield more focused results. But even simple terms like `"crowd"`, `"outdoor event"`, or `"forest animals"` can surface useful matches.
</Tip>
