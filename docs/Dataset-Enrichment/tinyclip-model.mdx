---
title: TinyCLIP Base Embedding Model
description: Learn about TinyCLIP, Visual Layer's new base embedding model that enhances visual similarity search and free search capabilities.
---

<Card title="How This Helps" icon="cpu">
TinyCLIP is Visual Layer's latest base embedding model that provides enhanced visual understanding and improved search capabilities across your datasets. It offers better semantic understanding while maintaining computational efficiency.
</Card>

## Overview

TinyCLIP is a compact vision-language model that serves as Visual Layer's new base embedding system for visual similarity search and free search functionality. This model provides:

- Enhanced embedding quality for more accurate visual similarity matching
- Improved semantic understanding for better search results
- Configurable similarity thresholds optimized for different use cases
- Better clustering performance for dataset exploration

## Key Features

### Enhanced Visual Similarity Search
TinyCLIP provides more accurate visual similarity matching compared to previous models, enabling you to find truly similar images and objects with improved precision.

### Configurable Similarity Thresholds
The model allows for customizable visual similarity thresholds, letting you adjust the sensitivity of similarity matching based on your specific needs:

- **Higher thresholds**: More precise matches, fewer but highly similar results
- **Lower thresholds**: Broader matching, more results with varied similarity levels

### Improved Clustering
TinyCLIP generates embeddings that create more meaningful clusters, helping you discover patterns and organize your visual data more effectively.

## Model Specifications

<div className="integrations-table">

| Specification | Details |
|---------------|---------|
| **Model Type** | Vision-Language Embedding Model |
| **Task Types** | Visual similarity search, free search, clustering |
| **Input Types** | Images, video frames |
| **Output** | High-dimensional embeddings for similarity computation |
| **Performance** | Optimized for accuracy and computational efficiency |

</div>

## Configuration Options

### Visual Similarity Thresholds

TinyCLIP supports configurable similarity thresholds that can be adjusted per model to optimize results for your specific use case:

<Steps>
<Step title="Access Model Settings">
Navigate to your dataset settings or contact your Visual Layer administrator to configure similarity thresholds.
</Step>

<Step title="Adjust Threshold Values">
Set appropriate threshold values based on your requirements:
- Use higher values (0.7-0.9) for precise, highly similar matches
- Use moderate values (0.5-0.7) for balanced similarity detection  
- Use lower values (0.3-0.5) for broader, more exploratory matching
</Step>

<Step title="Test and Refine">
Run similarity searches with your configured thresholds and adjust as needed based on result quality.
</Step>
</Steps>

## Best Practices

### Threshold Configuration
- Start with moderate threshold values and adjust based on your dataset characteristics
- Consider your use case: precision-focused tasks need higher thresholds, exploration benefits from lower thresholds
- Test threshold settings with representative samples from your dataset

### Dataset Optimization
- TinyCLIP works best with diverse, high-quality image datasets
- Ensure images have sufficient resolution for optimal embedding generation
- Consider image preprocessing to standardize input quality

## Troubleshooting

### Common Issues

#### Clusters Appear Smaller Than Expected
If you notice that TinyCLIP generates more, smaller clusters compared to previous models:

1. **Check similarity thresholds**: Lower thresholds may be needed to achieve desired cluster sizes
2. **Review dataset characteristics**: TinyCLIP may be more sensitive to subtle differences in your images
3. **Adjust clustering parameters**: Contact support to optimize clustering settings for your dataset

#### Duplicate Detection Sensitivity
If duplicate detection results seem different from previous models:

1. **Verify threshold settings**: TinyCLIP may require different threshold values for optimal duplicate detection
2. **Compare with reference datasets**: Test on known duplicate pairs to calibrate thresholds
3. **Consider dataset-specific tuning**: Different image types may need customized threshold configurations

<Note>
TinyCLIP represents a significant upgrade in embedding quality. Some differences in clustering and similarity results compared to previous models are expected as the model provides more nuanced understanding of visual content.
</Note>

## Support

For questions about TinyCLIP configuration, threshold optimization, or troubleshooting:

<Card title="Contact Support" href="mailto:support@visual-layer.com">
Reach out to our team for personalized assistance with TinyCLIP configuration and optimization.
</Card>